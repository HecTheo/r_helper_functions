#, 'motion'
)]
testing_data = data_[data_$topic == 'opinion_pos', c('veracity'
#, 'concr_mean_stemmed'
#, 'lcm'
, 'ner_sum'
#, 'rm_bond'
#, 'person_index_weighted'
#, 'specificity_zhou_burgoon2'
#, 'motion'
)]
lda.fit_cv = train(veracity ~ .
, data=training_data
, method="lda",
trControl = trainControl(method = "LOOCV")
)
testing_data$pred = predict(lda.fit_cv, testing_data)
caret::confusionMatrix(testing_data$pred, testing_data$veracity)
data_for_classification = data[data$topic == 'opinion_neg', c('veracity'
#, 'concr_mean_stemmed'
#, 'lcm'
#, 'ner_sum'
, 'rm_bond'
#, 'person_index_weighted'
#, 'specificity_zhou_burgoon2'
#, 'motion'
)]
data_for_classification = na.omit(data_for_classification)
data_for_classification$veracity = as.factor(data_for_classification$veracity)
lda_loocv = lda(veracity~.
, data_for_classification
, CV=T)
data_for_classification$pred = lda_loocv$class
caret::confusionMatrix(data_for_classification$pred, data_for_classification$veracity)
data_for_classification = data[data$topic == 'opinion_pos', c('veracity'
#, 'concr_mean_stemmed'
#, 'lcm'
#, 'ner_sum'
, 'rm_bond'
#, 'person_index_weighted'
#, 'specificity_zhou_burgoon2'
#, 'motion'
)]
data_for_classification = na.omit(data_for_classification)
data_for_classification$veracity = as.factor(data_for_classification$veracity)
lda_loocv = lda(veracity~.
, data_for_classification
, CV=T)
data_for_classification$pred = lda_loocv$class
caret::confusionMatrix(data_for_classification$pred, data_for_classification$veracity)
training_data = data_[data_$topic  == 'opinion_neg', c('veracity'
#, 'concr_mean_stemmed'
#, 'lcm'
#, 'ner_sum'
, 'rm_bond'
#, 'person_index_weighted'
#, 'specificity_zhou_burgoon2'
#, 'motion'
)]
testing_data = data_[data_$topic == 'opinion_pos', c('veracity'
#, 'concr_mean_stemmed'
#, 'lcm'
#, 'ner_sum'
, 'rm_bond'
#, 'person_index_weighted'
#, 'specificity_zhou_burgoon2'
#, 'motion'
)]
lda.fit_cv = train(veracity ~ .
, data=training_data
, method="lda",
trControl = trainControl(method = "LOOCV")
)
testing_data$pred = predict(lda.fit_cv, testing_data)
caret::confusionMatrix(testing_data$pred, testing_data$veracity)
training_data = data_[data_$topic  == 'opinion_pos', c('veracity'
#, 'concr_mean_stemmed'
#, 'lcm'
#, 'ner_sum'
, 'rm_bond'
#, 'person_index_weighted'
#, 'specificity_zhou_burgoon2'
#, 'motion'
)]
testing_data = data_[data_$topic == 'opinion_neg', c('veracity'
#, 'concr_mean_stemmed'
#, 'lcm'
#, 'ner_sum'
, 'rm_bond'
#, 'person_index_weighted'
#, 'specificity_zhou_burgoon2'
#, 'motion'
)]
lda.fit_cv = train(veracity ~ .
, data=training_data
, method="lda",
trControl = trainControl(method = "LOOCV")
)
testing_data$pred = predict(lda.fit_cv, testing_data)
caret::confusionMatrix(testing_data$pred, testing_data$veracity)
data_for_classification = data[data$topic == 'opinion_pos', c('veracity'
#, 'concr_mean_stemmed'
#, 'lcm'
#, 'ner_sum'
#, 'rm_bond'
, 'person_index_weighted'
#, 'specificity_zhou_burgoon2'
#, 'motion'
)]
data_for_classification = na.omit(data_for_classification)
data_for_classification$veracity = as.factor(data_for_classification$veracity)
lda_loocv = lda(veracity~.
, data_for_classification
, CV=T)
data_for_classification$pred = lda_loocv$class
caret::confusionMatrix(data_for_classification$pred, data_for_classification$veracity)
data_for_classification = data[data$topic == 'opinion_neg', c('veracity'
#, 'concr_mean_stemmed'
#, 'lcm'
#, 'ner_sum'
#, 'rm_bond'
, 'person_index_weighted'
#, 'specificity_zhou_burgoon2'
#, 'motion'
)]
data_for_classification = na.omit(data_for_classification)
data_for_classification$veracity = as.factor(data_for_classification$veracity)
lda_loocv = lda(veracity~.
, data_for_classification
, CV=T)
data_for_classification$pred = lda_loocv$class
caret::confusionMatrix(data_for_classification$pred, data_for_classification$veracity)
training_data = data_[data_$topic  == 'opinion_pos', c('veracity'
#, 'concr_mean_stemmed'
#, 'lcm'
#, 'ner_sum'
#, 'rm_bond'
, 'person_index_weighted'
#, 'specificity_zhou_burgoon2'
#, 'motion'
)]
testing_data = data_[data_$topic == 'opinion_neg', c('veracity'
#, 'concr_mean_stemmed'
#, 'lcm'
#, 'ner_sum'
#, 'rm_bond'
, 'person_index_weighted'
#, 'specificity_zhou_burgoon2'
#, 'motion'
)]
lda.fit_cv = train(veracity ~ .
, data=training_data
, method="lda",
trControl = trainControl(method = "LOOCV")
)
testing_data$pred = predict(lda.fit_cv, testing_data)
caret::confusionMatrix(testing_data$pred, testing_data$veracity)
training_data = data_[data_$topic  == 'opinion_neg', c('veracity'
#, 'concr_mean_stemmed'
#, 'lcm'
#, 'ner_sum'
#, 'rm_bond'
, 'person_index_weighted'
#, 'specificity_zhou_burgoon2'
#, 'motion'
)]
testing_data = data_[data_$topic == 'opinion_pos', c('veracity'
#, 'concr_mean_stemmed'
#, 'lcm'
#, 'ner_sum'
#, 'rm_bond'
, 'person_index_weighted'
#, 'specificity_zhou_burgoon2'
#, 'motion'
)]
lda.fit_cv = train(veracity ~ .
, data=training_data
, method="lda",
trControl = trainControl(method = "LOOCV")
)
testing_data$pred = predict(lda.fit_cv, testing_data)
caret::confusionMatrix(testing_data$pred, testing_data$veracity)
data_for_classification = data[data$topic == 'opinion_neg', c('veracity'
#, 'concr_mean_stemmed'
#, 'lcm'
#, 'ner_sum'
#, 'rm_bond'
#, 'person_index_weighted'
, 'specificity_zhou_burgoon2'
#, 'motion'
)]
data_for_classification = na.omit(data_for_classification)
data_for_classification$veracity = as.factor(data_for_classification$veracity)
lda_loocv = lda(veracity~.
, data_for_classification
, CV=T)
data_for_classification$pred = lda_loocv$class
caret::confusionMatrix(data_for_classification$pred, data_for_classification$veracity)
data_for_classification = data[data$topic == 'opinion_pos', c('veracity'
#, 'concr_mean_stemmed'
#, 'lcm'
#, 'ner_sum'
#, 'rm_bond'
#, 'person_index_weighted'
, 'specificity_zhou_burgoon2'
#, 'motion'
)]
data_for_classification = na.omit(data_for_classification)
data_for_classification$veracity = as.factor(data_for_classification$veracity)
lda_loocv = lda(veracity~.
, data_for_classification
, CV=T)
data_for_classification$pred = lda_loocv$class
caret::confusionMatrix(data_for_classification$pred, data_for_classification$veracity)
training_data = data_[data_$topic  == 'opinion_neg', c('veracity'
#, 'concr_mean_stemmed'
#, 'lcm'
#, 'ner_sum'
#, 'rm_bond'
#, 'person_index_weighted'
, 'specificity_zhou_burgoon2'
#, 'motion'
)]
testing_data = data_[data_$topic == 'opinion_pos', c('veracity'
#, 'concr_mean_stemmed'
#, 'lcm'
#, 'ner_sum'
#, 'rm_bond'
#, 'person_index_weighted'
, 'specificity_zhou_burgoon2'
#, 'motion'
)]
lda.fit_cv = train(veracity ~ .
, data=training_data
, method="lda",
trControl = trainControl(method = "LOOCV")
)
testing_data$pred = predict(lda.fit_cv, testing_data)
caret::confusionMatrix(testing_data$pred, testing_data$veracity)
training_data = data_[data_$topic  == 'opinion_pos', c('veracity'
#, 'concr_mean_stemmed'
#, 'lcm'
#, 'ner_sum'
#, 'rm_bond'
#, 'person_index_weighted'
, 'specificity_zhou_burgoon2'
#, 'motion'
)]
testing_data = data_[data_$topic == 'opinion_neg', c('veracity'
#, 'concr_mean_stemmed'
#, 'lcm'
#, 'ner_sum'
#, 'rm_bond'
#, 'person_index_weighted'
, 'specificity_zhou_burgoon2'
#, 'motion'
)]
lda.fit_cv = train(veracity ~ .
, data=training_data
, method="lda",
trControl = trainControl(method = "LOOCV")
)
testing_data$pred = predict(lda.fit_cv, testing_data)
caret::confusionMatrix(testing_data$pred, testing_data$veracity)
names(data)
#intratextual analysis
setwd('/Users/bennettkleinberg/GitHub/r_helper_functions')
source('./get_narrative_dim.R')
data$new_filename
sentiment_data = data[data$topic %in% c('opinion_pos'
, 'opinion_neg'
, 'intentions_ms_exp1'
, 'intentions_ms_exp2'),]
setwd('/Users/bennettkleinberg/GitHub/r_helper_functions')
source('./get_narrative_dim.R')
sentiment_data = data[data$topic %in% c('opinion_pos'
, 'opinion_neg'
, 'intentions_ms_exp1'
, 'intentions_ms_exp2'),]
concreteness_structure = get_narrative_dim(txt_input_col = sentiment_data$text
, txt_id_col = sentiment_data$new_filename
, transform_values = T
, dimension = 'concreteness'
, low_pass_filter_size = 5
, stemming = F
, bins = 100
, transposing = F)
t_concr_struc = t(concreteness_structure)
dim(concreteness_structure)
plot(concreteness_structure$intentions_ms_exp1_1809
, type='h')
save(concreteness_structure
, t_concr_struc
, file = '/Users/bennettkleinberg/Documents/Research/CBDMI_Schiphol/concreteness_paper/structure_data_concreteness.RData')
names(data)
data_min = data[, c('topic', 'veracity', 'new_filename')]
names(data_min)
data_min
t_concr_struc
data_min
#merge to data
structure.concreteness = merge(as.data.frame(t_concr_struc), data_min, by='new_filename')
#merge to data
t_concr_struc = as.data.frame(t_concr_struc)
t_concr_struc
t_concr_struc$new_filename = row.names(t_concr_struc)
structure.concreteness = merge(t_concr_struc, data_min, by='new_filename')
dim(structure.concreteness)
structure.concreteness
avg_veracity_topic = aggregate(structure.concreteness[, 2:101]
, by = list(structure.concreteness$topic, structure.concreteness$veracity), mean)
avg_veracity_topic
avg_veracity_topic$dataset = paste(avg_veracity_topic$Group.1, avg_veracity_topic$Group.2, sep="_")
avg_veracity_topic$dataset
names(avg_veracity_topic)
avg_veracity_topic = avg_veracity_topic[, -c(1:2)]
concr_avg = t(avg_veracity_topic)
concr_avg
concr_avg = as.data.frame(t(avg_veracity_topic))
concr_avg
colnames(concr_avg)
concr_avg$dataset
concr_avg[101,]
colnames(concr_avg) = concr_avg[101,]
colnames(concr_avg)
avg_veracity_topic$dataset
colnames(concr_avg) = avg_veracity_topic$dataset
colnames(concr_avg)
plot(concr_avg$intentions_ms_exp1_d
, type='h')
concr_avg$intentions_ms_exp1_d
concr_avg
concr_avg[1:100, ]
concr_avg = concr_avg[1:100, ]
plot(concr_avg$intentions_ms_exp1_d
, type='h')
concr_avg$intentions_ms_exp1_d
avg_veracity_topic
concr_avg = as.numeric(concr_avg)
source('toNumeric')
#intratextual analysis
setwd('/Users/bennettkleinberg/GitHub/r_helper_functions')
source('toNumeric.R')
concr_avg = toNumeric(concr_avg)
concr_avg
avg_veracity_topic = aggregate(structure.concreteness[, 2:101]
, by = list(structure.concreteness$topic, structure.concreteness$veracity), mean)
avg_veracity_topic$dataset = paste(avg_veracity_topic$Group.1, avg_veracity_topic$Group.2, sep="_")
avg_veracity_topic = avg_veracity_topic[, -c(1:2)]
avg_veracity_topic
concr_avg = as.data.frame(t(avg_veracity_topic))
colnames(concr_avg) = avg_veracity_topic$dataset
concr_avg = concr_avg[1:100, ]
concr_avg$intentions_ms_exp1_d
toNumeric(concr_avg$intentions_ms_exp1_d)
plot(toNumeric(concr_avg$intentions_ms_exp1_d)
, type='h')
plot(toNumeric(concr_avg$intentions_ms_exp1_t)
, type='h')
plot(toNumeric(concr_avg$intentions_ms_exp1_d)
, type='h'
, ylim = c(-1, 1))
plot(toNumeric(concr_avg$intentions_ms_exp1_t)
, type='h'
, ylim = c(-1, 1))
plot(toNumeric(concr_avg$intentions_ms_exp2_d)
, type='h'
, ylim = c(-1, 1))
plot(toNumeric(concr_avg$intentions_ms_exp2_t)
, type='h'
, ylim = c(-1, 1))
plot(toNumeric(concr_avg$opinion_neg_d)
, type='h'
, ylim = c(-1, 1))
plot(toNumeric(concr_avg$opinion_neg_t)
, type='h'
, ylim = c(-1, 1))
plot(toNumeric(concr_avg$opinion_pos_d)
, type='h'
, ylim = c(-1, 1))
plot(toNumeric(concr_avg$opinion_pos_t)
, type='h'
, ylim = c(-1, 1))
plot(toNumeric(concr_avg$intentions_ms_exp1_d)
, type='h'
, ylim = c(-1, 1)
, xlim = c(-.5, .5))
plot(toNumeric(concr_avg$intentions_ms_exp1_d)
, type='h'
, ylim = c(-.5, .5))
plot(toNumeric(concr_avg$intentions_ms_exp1_t)
, type='h'
, ylim = c(-.5, .5))
plot(toNumeric(concr_avg$intentions_ms_exp2_d)
, type='h'
, ylim = c(-.5, .5))
plot(toNumeric(concr_avg$intentions_ms_exp2_t)
, type='h'
, ylim = c(-.5, .5))
plot(toNumeric(concr_avg$intentions_ms_exp2_d)
, type='h'
, ylim = c(-.5, .5))
plot(toNumeric(concr_avg$intentions_ms_exp2_t)
, type='h'
, ylim = c(-.5, .5))
plot(toNumeric(concr_avg$opinion_neg_d)
, type='h'
, ylim = c(-.5, .5))
plot(toNumeric(concr_avg$opinion_neg_t)
, type='h'
, ylim = c(-.5, .5))
plot(toNumeric(concr_avg$opinion_pos_d)
, type='h'
, ylim = c(-.5, .5))
plot(toNumeric(concr_avg$opinion_pos_t)
, type='h'
, ylim = c(-.5, .5))
#GLMM with random intercept for dataset
require(lme4)
lmer
data$veracity
levels(data$veracity)
data$veracity = as.factor(data$veracity)
data$veracity
levels(data$veracity)
levels(data$veracity) = c(1, 0)
levels(data$veracity)
data$topic
log_glmm = lmer(veracity ~ concr_mean_stemmed + lcm + ner_sum + rm_bond + person_index_weighted + specificity_zhou_burgoon2 + motion + abstraction_index + rm_bond+(1|topic), data=data)
data$veracity
toNumeric(data$veracity)
data$veracity = toNumeric(data$veracity)
log_glmm = lmer(veracity ~ concr_mean_stemmed + lcm + ner_sum + rm_bond + person_index_weighted + specificity_zhou_burgoon2 + motion + abstraction_index + rm_bond+(1|topic), data=data)
log_glmm
log_glmm = lmer(veracity ~ concr_mean_stemmed + lcm + ner_sum + rm_bond + person_index_weighted + specificity_zhou_burgoon2 + motion + abstraction_index + rm_bond+(1|topic), data=data, family="binomial")
log_glmm
log_glmm
?lmer
coef(log_glmm)
exp(-3.28)
anova(log_glmm)
log_glmm = lme(veracity ~ concr_mean_stemmed + lcm + ner_sum + rm_bond + person_index_weighted + specificity_zhou_burgoon2 + motion + abstraction_index + rm_bond+(1|topic), data=data, family="binomial")
require(nlme)
log_glmm = lme(veracity ~ concr_mean_stemmed + lcm + ner_sum + rm_bond + person_index_weighted + specificity_zhou_burgoon2 + motion + abstraction_index + rm_bond+(1|topic), data=data, family="binomial")
install.packages("lmerTest")
require(lmerTest)
anova(log_glmm)
summary(log_glmm)
exp(-10)
predict(log_glmm, data)
predict(log_glmm, data, type = 'response')
pred = predict(log_glmm, data, type = 'response')
data$pred = predict(log_glmm, data, type = 'response')
data$pred = ifelse(data$pred > .5, 1, 0)
table(data$veracity, data$pred)
confusionMatrix(table(data$veracity, data$pred))
training_indices = createDataPartition(y = data$veracity
, p = .8
, list = FALSE)
training_indices
set.seed(42)
training_indices = createDataPartition(y = data$veracity
, p = .8
, list = FALSE)
training_data = data[training_indices, ]
training_data
testing_data = data[-training_indices, ]
log_glmm = lmer(veracity ~ concr_mean_stemmed + lcm + ner_sum + rm_bond + person_index_weighted + specificity_zhou_burgoon2 + motion + abstraction_index + rm_bond+(1|topic), data=training_data, family="binomial")
#GLMM with random intercept for dataset
require(lme4)
log_glmm = lme4::lmer(veracity ~ concr_mean_stemmed + lcm + ner_sum + rm_bond + person_index_weighted + specificity_zhou_burgoon2 + motion + abstraction_index + rm_bond+(1|topic), data=training_data, family="binomial")
testing_data$pred = predict(log_glmm, testing_data, type = 'response')
testing_data$pred
testing_data$pred = predict(log_glmm, testing_data, type = 'response')
testing_data$pred = ifelse(testing_data$pred > .5, 1, 0)
confusionMatrix(table(testing_data$veracity, testing_data$pred))
log_glmm
log_glmm = lmer(veracity ~ concr_mean_stemmed + lcm + ner_sum + rm_bond + person_index_weighted + specificity_zhou_burgoon2 + motion + abstraction_index + rm_bond+(1|topic), data=data, family="binomial")
log_glmm = lme4::lmer(veracity ~ concr_mean_stemmed + lcm + ner_sum + rm_bond + person_index_weighted + specificity_zhou_burgoon2 + motion + abstraction_index + rm_bond+(1|topic), data=data, family="binomial")
log_glmm
set.seed(42)
training_indices = createDataPartition(y = data$veracity
, p = .8
, list = FALSE)
training_data = data[training_indices, ]
testing_data = data[-training_indices, ]
log_glmm = lme4::lmer(veracity ~ concr_mean_stemmed + lcm + ner_sum + rm_bond + person_index_weighted + specificity_zhou_burgoon2 + motion + abstraction_index + rm_bond+(1|topic), data=training_data, family="binomial")
testing_data$pred = predict(log_glmm, testing_data, type = 'response')
testing_data$pred = ifelse(testing_data$pred > .5, 0, 1)
confusionMatrix(table(testing_data$veracity, testing_data$pred))
testing_data$pred = ifelse(testing_data$pred > .5, 1, 0)
confusionMatrix(table(testing_data$veracity, testing_data$pred))
set.seed(42)
training_indices = createDataPartition(y = data$veracity
, p = .8
, list = FALSE)
training_data = data[training_indices, ]
testing_data = data[-training_indices, ]
log_glmm = lme4::lmer(veracity ~ concr_mean_stemmed + lcm + ner_sum + rm_bond + person_index_weighted + specificity_zhou_burgoon2 + motion + abstraction_index + rm_bond+(1|topic), data=training_data, family="binomial")
testing_data$pred = predict(log_glmm, testing_data, type = 'response')
testing_data$pred = ifelse(testing_data$pred > .5, 1, 0)
confusionMatrix(table(testing_data$veracity, testing_data$pred))
set.seed(43)
training_indices = createDataPartition(y = data$veracity
, p = .8
, list = FALSE)
training_data = data[training_indices, ]
testing_data = data[-training_indices, ]
log_glmm = lme4::lmer(veracity ~ concr_mean_stemmed + lcm + ner_sum + rm_bond + person_index_weighted + specificity_zhou_burgoon2 + motion + abstraction_index + rm_bond+(1|topic), data=training_data, family="binomial")
testing_data$pred = predict(log_glmm, testing_data, type = 'response')
testing_data$pred = ifelse(testing_data$pred > .5, 1, 0)
confusionMatrix(table(testing_data$veracity, testing_data$pred))
