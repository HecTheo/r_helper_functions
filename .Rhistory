# RF
rf_controls = trainControl(method="repeatedcv"
, number = 5
, repeats = 10
, selectionFunction = "oneSE"
, classProbs = T
, summaryFunction = twoClassSummary
, savePredictions = F
#, sampling = 'none'
)
rf_grid = data.frame(mtry = seq(2, 10, 2))
rf_5_10 = train(outcome_class ~ .
, data = training_data
, method = "ranger"
, trControl = rf_controls
, preProcess = c('nzv', 'center', 'scale')
, metric = 'ROC'
, importance = 'impurity'
#, tuneGrid = rf_grid
#, tuneLength = 10
)
## inspect mtry hyperparam tuning
#plot(rf_5_10)
## feature inspection
#names(training_data)[nearZeroVar(training_data)]
## validate on test data
testing_data$pred = predict(rf_5_10, testing_data)
testing_data$probs = predict(rf_5_10, testing_data, type = 'prob')[,2]
## confusion matrix
confusion_matrix = caret::confusionMatrix(testing_data$pred, testing_data$outcome_class)
confusion_matrix
precision(testing_data$pred, testing_data$outcome_class, relevant = 'S')
recall(testing_data$pred, testing_data$outcome_class, relevant = 'S')
F_meas(testing_data$pred, testing_data$outcome_class, relevant = 'S')
precision(testing_data$pred, testing_data$outcome_class, relevant = 'N')
recall(testing_data$pred, testing_data$outcome_class, relevant = 'N')
F_meas(testing_data$pred, testing_data$outcome_class, relevant = 'N')
## ROC
roc_data = roc(response = testing_data$outcome_class
, predictor = testing_data$probs
, ci=T)
roc_data
set.seed(84)
# define data
data_ml = data_liwc_psych
#data_ml$outcome_class = as.factor(data_ml$outcome_class)
#levels(data_ml$outcome_class) = c('N', 'S', 'N', 'S')
#data_ml = data_ml[data_ml$outcome_class %in% c('PS', 'PN'), ]
data_ml$outcome_class = as.factor(data_ml$outcome_class)
levels(data_ml$outcome_class) = make.names(levels(data_ml$outcome_class))
#no. of features
ncol(data_ml)-1
# train/test split
in_training = createDataPartition(y = data_ml$outcome_class
, p = .6
, list = FALSE
)
training_data = data_ml[ in_training,]
testing_data = data_ml[-in_training,]
prop.table(table(training_data$outcome_class))
prop.table(table(testing_data$outcome_class))
# RF
rf_controls = trainControl(method="repeatedcv"
, number = 5
, repeats = 10
, selectionFunction = "oneSE"
, classProbs = T
, summaryFunction = twoClassSummary
, savePredictions = F
#, sampling = 'none'
)
rf_grid = data.frame(mtry = seq(2, 10, 2))
rf_5_10 = train(outcome_class ~ .
, data = training_data
, method = "ranger"
, trControl = rf_controls
, preProcess = c('nzv', 'center', 'scale')
, metric = 'ROC'
, importance = 'impurity'
#, tuneGrid = rf_grid
#, tuneLength = 10
)
## inspect mtry hyperparam tuning
#plot(rf_5_10)
## feature inspection
#names(training_data)[nearZeroVar(training_data)]
## validate on test data
testing_data$pred = predict(rf_5_10, testing_data)
testing_data$probs = predict(rf_5_10, testing_data, type = 'prob')[,2]
## confusion matrix
confusion_matrix = caret::confusionMatrix(testing_data$pred, testing_data$outcome_class)
confusion_matrix
precision(testing_data$pred, testing_data$outcome_class, relevant = 'S')
recall(testing_data$pred, testing_data$outcome_class, relevant = 'S')
F_meas(testing_data$pred, testing_data$outcome_class, relevant = 'S')
precision(testing_data$pred, testing_data$outcome_class, relevant = 'N')
recall(testing_data$pred, testing_data$outcome_class, relevant = 'N')
F_meas(testing_data$pred, testing_data$outcome_class, relevant = 'N')
## ROC
roc_data = roc(response = testing_data$outcome_class
, predictor = testing_data$probs
, ci=T)
roc_data
set.seed(84)
# define data
data_ml = data_liwc_full
#data_ml$outcome_class = as.factor(data_ml$outcome_class)
#levels(data_ml$outcome_class) = c('N', 'S', 'N', 'S')
#data_ml = data_ml[data_ml$outcome_class %in% c('PS', 'PN'), ]
data_ml$outcome_class = as.factor(data_ml$outcome_class)
levels(data_ml$outcome_class) = make.names(levels(data_ml$outcome_class))
#no. of features
ncol(data_ml)-1
# train/test split
in_training = createDataPartition(y = data_ml$outcome_class
, p = .6
, list = FALSE
)
training_data = data_ml[ in_training,]
testing_data = data_ml[-in_training,]
prop.table(table(training_data$outcome_class))
prop.table(table(testing_data$outcome_class))
# RF
rf_controls = trainControl(method="repeatedcv"
, number = 5
, repeats = 10
, selectionFunction = "oneSE"
, classProbs = T
, summaryFunction = twoClassSummary
, savePredictions = F
#, sampling = 'none'
)
rf_grid = data.frame(mtry = seq(2, 10, 2))
rf_5_10 = train(outcome_class ~ .
, data = training_data
, method = "ranger"
, trControl = rf_controls
, preProcess = c('nzv', 'center', 'scale')
, metric = 'ROC'
, importance = 'impurity'
#, tuneGrid = rf_grid
#, tuneLength = 10
)
## inspect mtry hyperparam tuning
#plot(rf_5_10)
## feature inspection
#names(training_data)[nearZeroVar(training_data)]
## validate on test data
testing_data$pred = predict(rf_5_10, testing_data)
testing_data$probs = predict(rf_5_10, testing_data, type = 'prob')[,2]
## confusion matrix
confusion_matrix = caret::confusionMatrix(testing_data$pred, testing_data$outcome_class)
confusion_matrix
precision(testing_data$pred, testing_data$outcome_class, relevant = 'S')
recall(testing_data$pred, testing_data$outcome_class, relevant = 'S')
F_meas(testing_data$pred, testing_data$outcome_class, relevant = 'S')
precision(testing_data$pred, testing_data$outcome_class, relevant = 'N')
recall(testing_data$pred, testing_data$outcome_class, relevant = 'N')
F_meas(testing_data$pred, testing_data$outcome_class, relevant = 'N')
## ROC
roc_data = roc(response = testing_data$outcome_class
, predictor = testing_data$probs
, ci=T)
roc_data
set.seed(84)
# define data
data_ml = data_unigrams
#data_ml$outcome_class = as.factor(data_ml$outcome_class)
#levels(data_ml$outcome_class) = c('N', 'S', 'N', 'S')
#data_ml = data_ml[data_ml$outcome_class %in% c('PS', 'PN'), ]
data_ml$outcome_class = as.factor(data_ml$outcome_class)
levels(data_ml$outcome_class) = make.names(levels(data_ml$outcome_class))
#no. of features
ncol(data_ml)-1
# train/test split
in_training = createDataPartition(y = data_ml$outcome_class
, p = .6
, list = FALSE
)
training_data = data_ml[ in_training,]
testing_data = data_ml[-in_training,]
prop.table(table(training_data$outcome_class))
prop.table(table(testing_data$outcome_class))
# RF
rf_controls = trainControl(method="repeatedcv"
, number = 5
, repeats = 10
, selectionFunction = "oneSE"
, classProbs = T
, summaryFunction = twoClassSummary
, savePredictions = F
#, sampling = 'none'
)
rf_grid = data.frame(mtry = seq(2, 10, 2))
rf_5_10 = train(outcome_class ~ .
, data = training_data
, method = "ranger"
, trControl = rf_controls
, preProcess = c('nzv', 'center', 'scale')
, metric = 'ROC'
, importance = 'impurity'
#, tuneGrid = rf_grid
#, tuneLength = 10
)
## inspect mtry hyperparam tuning
#plot(rf_5_10)
## feature inspection
#names(training_data)[nearZeroVar(training_data)]
## validate on test data
testing_data$pred = predict(rf_5_10, testing_data)
testing_data$probs = predict(rf_5_10, testing_data, type = 'prob')[,2]
## confusion matrix
confusion_matrix = caret::confusionMatrix(testing_data$pred, testing_data$outcome_class)
confusion_matrix
precision(testing_data$pred, testing_data$outcome_class, relevant = 'S')
recall(testing_data$pred, testing_data$outcome_class, relevant = 'S')
F_meas(testing_data$pred, testing_data$outcome_class, relevant = 'S')
precision(testing_data$pred, testing_data$outcome_class, relevant = 'N')
recall(testing_data$pred, testing_data$outcome_class, relevant = 'N')
F_meas(testing_data$pred, testing_data$outcome_class, relevant = 'N')
## ROC
roc_data = roc(response = testing_data$outcome_class
, predictor = testing_data$probs
, ci=T)
roc_data
set.seed(84)
# define data
data_ml = data_bigrams
#data_ml$outcome_class = as.factor(data_ml$outcome_class)
#levels(data_ml$outcome_class) = c('N', 'S', 'N', 'S')
#data_ml = data_ml[data_ml$outcome_class %in% c('PS', 'PN'), ]
data_ml$outcome_class = as.factor(data_ml$outcome_class)
levels(data_ml$outcome_class) = make.names(levels(data_ml$outcome_class))
#no. of features
ncol(data_ml)-1
# train/test split
in_training = createDataPartition(y = data_ml$outcome_class
, p = .6
, list = FALSE
)
training_data = data_ml[ in_training,]
testing_data = data_ml[-in_training,]
prop.table(table(training_data$outcome_class))
prop.table(table(testing_data$outcome_class))
# RF
rf_controls = trainControl(method="repeatedcv"
, number = 5
, repeats = 10
, selectionFunction = "oneSE"
, classProbs = T
, summaryFunction = twoClassSummary
, savePredictions = F
#, sampling = 'none'
)
rf_grid = data.frame(mtry = seq(2, 10, 2))
rf_5_10 = train(outcome_class ~ .
, data = training_data
, method = "ranger"
, trControl = rf_controls
, preProcess = c('nzv', 'center', 'scale')
, metric = 'ROC'
, importance = 'impurity'
#, tuneGrid = rf_grid
#, tuneLength = 10
)
## inspect mtry hyperparam tuning
#plot(rf_5_10)
## feature inspection
#names(training_data)[nearZeroVar(training_data)]
## validate on test data
testing_data$pred = predict(rf_5_10, testing_data)
testing_data$probs = predict(rf_5_10, testing_data, type = 'prob')[,2]
## confusion matrix
confusion_matrix = caret::confusionMatrix(testing_data$pred, testing_data$outcome_class)
confusion_matrix
precision(testing_data$pred, testing_data$outcome_class, relevant = 'S')
recall(testing_data$pred, testing_data$outcome_class, relevant = 'S')
F_meas(testing_data$pred, testing_data$outcome_class, relevant = 'S')
precision(testing_data$pred, testing_data$outcome_class, relevant = 'N')
recall(testing_data$pred, testing_data$outcome_class, relevant = 'N')
F_meas(testing_data$pred, testing_data$outcome_class, relevant = 'N')
## ROC
roc_data = roc(response = testing_data$outcome_class
, predictor = testing_data$probs
, ci=T)
roc_data
###############################################################################
##### YOUTUBE ADS DETECTION #####
##### KLEINBERG, MOZES, VAN DER VEGT ###
###############################################################################
# PREPARATION
## clear ws
rm(list = ls())
## load deps
require(caret)
require(e1071)
require(pROC)
require(tm)
require(data.table)
require(ggplot2)
require(tidyr)
require(MLmetrics)
setwd('/Users/bennettkleinberg/GitHub/r_helper_functions')
source('./txt_df_from_dir.R')
source('./spacy_ner_r.R')
source('./spacy_pos_r.R')
source('./get_single_readability.R')
## set dir
setwd('/Users/bennettkleinberg/Documents/Research/CBDMI_Schiphol/youtube_ads/data/dataset/features')
# LOAD FEATURES AND DATA
#load('youtube_ads_feature_extraction_whole_transcripts.RData')
load('youtube_ads_feature_extraction_segments.RData')
###############################################################################
##### YOUTUBE ADS DETECTION #####
##### KLEINBERG, MOZES, VAN DER VEGT ###
###############################################################################
# PREPARATION
## clear ws
rm(list = ls())
## load deps
require(caret)
require(e1071)
require(pROC)
require(tm)
require(data.table)
require(ggplot2)
require(tidyr)
require(MLmetrics)
setwd('/Users/bennettkleinberg/GitHub/r_helper_functions')
source('./txt_df_from_dir.R')
source('./spacy_ner_r.R')
source('./spacy_pos_r.R')
source('./get_single_readability.R')
source('./ds_between_CI.R')
source('./dz_within_CI.R')
## set dir
setwd('/Users/bennettkleinberg/Documents/Research/CBDMI_Schiphol/youtube_ads/data/dataset/features')
# LOAD FEATURES AND DATA
#load('youtube_ads_feature_extraction_whole_transcripts.RData')
load('youtube_ads_feature_extraction_segments.RData')
#load('youtube_ads_ngrams_sparsity_90.RData')
# linguistic profile
ds_between_ci(data$WC, data$outcome_class, T, F)
data$outcome_class
# linguistic profile
data_profile = data[data$outcome_class %in% c('PS', 'PN'), ]
ds_between_ci(data$WC, data$outcome_class, T, F)
ds_between_ci(data_profile$WC, data_profile$outcome_class, T, F)
ds_between_ci(data_profile$ner_person, data_profile$outcome_class, T, F)
ds_between_ci(data_profile$ttr, data_profile$outcome_class, T, F)
ds_between_ci(data_profile$Tone, data_profile$outcome_class, T, F)
ds_between_ci(data_profile$Analytic, data_profile$outcome_class, T, F)
ds_between_ci(data_profile$rdb_fleschkincaid, data_profile$outcome_class, T, F)
###############################################################################
##### YOUTUBE ADS DETECTION #####
##### KLEINBERG, MOZES, VAN DER VEGT ###
###############################################################################
# PREPARATION
## clear ws
rm(list = ls())
## load deps
require(caret)
require(e1071)
require(pROC)
require(tm)
require(data.table)
require(ggplot2)
require(tidyr)
require(MLmetrics)
setwd('/Users/bennettkleinberg/GitHub/r_helper_functions')
source('./txt_df_from_dir.R')
source('./spacy_ner_r.R')
source('./spacy_pos_r.R')
source('./get_single_readability.R')
source('./ds_between_CI.R')
source('./dz_within_CI.R')
## set dir
setwd('/Users/bennettkleinberg/Documents/Research/CBDMI_Schiphol/youtube_ads/data/dataset/features')
# LOAD FEATURES AND DATA
#load('youtube_ads_feature_extraction_whole_transcripts.RData')
load('youtube_ads_feature_extraction_segments.RData')
data_pos = data[,c(105, 107:123)]
data_ner = data[,c(105, 130:147)]
data_rdb = data[,c(105, 124:129)]
data_liwc_summary = data[,c(105, 7:14)]
data_liwc_ling = data[,c(105, 15:35)]
data_liwc_psych = data[,c(105, 36:75)]
data_liwc_personal = data[,c(105, 76:81)]
data_liwc_informal = data[,c(105, 82:87)]
data_liwc_punct = data[,c(105, 88:99)]
data_liwc_full = data[,c(105, 7:99)]
set.seed(84)
# define data
data_ml = data_ner
data_ml$outcome_class = as.factor(data_ml$outcome_class)
levels(data_ml$outcome_class)
#levels(data_ml$outcome_class) = c('N', 'S', 'N', 'S')
levels(data_ml$outcome_class) = c('N', 'N', 'P', 'P')
#data_ml = data_ml[data_ml$outcome_class %in% c('PS', 'PN'), ]
data_ml$outcome_class = as.factor(data_ml$outcome_class)
levels(data_ml$outcome_class) = make.names(levels(data_ml$outcome_class))
ncol(data_ml)-1
# train/test split
in_training = createDataPartition(y = data_ml$outcome_class
, p = .6
, list = FALSE
)
training_data = data_ml[ in_training,]
testing_data = data_ml[-in_training,]
prop.table(table(training_data$outcome_class))
prop.table(table(testing_data$outcome_class))
# RF
rf_controls = trainControl(method="repeatedcv"
, number = 5
, repeats = 10
, selectionFunction = "oneSE"
, classProbs = T
, summaryFunction = twoClassSummary
, savePredictions = F
#, sampling = 'none'
)
rf_grid = data.frame(mtry = seq(2, 10, 2))
rf_5_10 = train(outcome_class ~ .
, data = training_data
, method = "ranger"
, trControl = rf_controls
, preProcess = c('nzv', 'center', 'scale')
, metric = 'ROC'
, importance = 'impurity'
#, tuneGrid = rf_grid
#, tuneLength = 10
)
## inspect mtry hyperparam tuning
#plot(rf_5_10)
## feature inspection
#names(training_data)[nearZeroVar(training_data)]
## validate on test data
testing_data$pred = predict(rf_5_10, testing_data)
testing_data$probs = predict(rf_5_10, testing_data, type = 'prob')[,2]
## confusion matrix
confusion_matrix = caret::confusionMatrix(testing_data$pred, testing_data$outcome_class)
confusion_matrix
#################################################
######### Ngram plus project ####################
######### BOW classification ####################
#################################################
#clear ws
rm(list = ls())
#set wd
setwd('/Users/bennettkleinberg/Documents/Research/CBDMI_Schiphol/concreteness_paper')
#load deps
require(caret)
require(e1071)
require(pROC)
require(tm)
require(ggplot2)
require(tidyr)
setwd('/Users/bennettkleinberg/GitHub/r_helper_functions')
source('./txt_df_from_dir.R')
source('./spacy_ner_r.R')
source('./spacy_pos_r.R')
source('./linguistic_category_model.R')
source('./calculate_concreteness.R')
source("./ds_between_ci.R")
source("./dz_within_ci.R")
load('/Users/bennettkleinberg/Documents/Research/CBDMI_Schiphol/concreteness_paper/final_data_concreteness_06022018.RData')
#people index
data$person_index_raw = data$ppron + data$social + data$ner_person_rel
data$person_index_weighted = (1*data$ppron + 2*data$social + 3*data$ner_person_rel*100)/(data$ppron + data$social + data$ner_person_rel*100)
#time index
data$time_index_past_raw = data$focuspast + data$ner_date_rel + data$ner_time_rel
data$time_index_past_weighted = (1*data$focuspast + 2*data$ner_date_rel + 3*data$ner_time_rel)/(data$focuspast + data$ner_date_rel + data$ner_time_rel)
data$time_index_present_raw = data$focuspresent + data$ner_date_rel + data$ner_time_rel
data$time_index_present_weighted = (1*data$focuspresent + 2*data$ner_date_rel + 3*data$ner_time_rel)/(data$focuspresent + data$ner_date_rel + data$ner_time_rel)
data$time_index_future_raw = data$focusfuture + data$ner_date_rel + data$ner_time_rel
data$time_index_future_weighted = (1*data$focusfuture + 2*data$ner_date_rel + 3*data$ner_time_rel)/(data$focusfuture + data$ner_date_rel + data$ner_time_rel)
#location index
data$location_index_raw = data$space + data$ner_facility_rel + data$ner_loc_rel + data$ner_gpe_rel
data$location_index_weighted = (1*data$space + 2*data$ner_facility_rel + 3*data$ner_loc_rel + 4*data$ner_gpe_rel)/(data$space + data$ner_facility_rel + data$ner_loc_rel + data$ner_gpe_rel)
#examples
which.min(data$abstraction_index)
min(data$abstraction_index)
data[which.min(data$abstraction_index), 'text']
data[which.max(data$abstraction_index), 'text']
data$text[order(data$abstraction_index)]
data$text[order(data$abstraction_index, decreasing = T)][1:5]
data$text[order(data$abstraction_index, decreasing = F)][1:5]
data$text[order(data$lcm, decreasing = F)][1:5]
data$text[order(data$lcm, decreasing = T)][1:5]
data_ = data[data$topic != 'bestfriend', ]
data_$text[order(data_$abstraction_index, decreasing = T)][1:5]
data_$text[order(data_$abstraction_index, decreasing = F)][1:5]
data_$text[order(data_$lcm, decreasing = F)][1:5]
data_$text[order(data_$lcm, decreasing = T)][1:5]
data_$text[order(data_$ner_sum, decreasing = T)][1:5]
data_$text[order(data_$ner_sum, decreasing = F)][1:5]
data_$text[order(data_$rm_bond, decreasing = F)][1:5]
data_$text[order(data_$rm_bond, decreasing = T)][1:5]
data$specificity_zhou_burgoon2 = data$i + data$we + data$you + data$shehe + data$they + data$pos_adv_rel*100 + data$pos_adj_rel*100 + data$percept + (data$percept*data$nwords)/100
data_ = data[data$topic != 'bestfriend', ]
data_$text[order(data_$specificity_zhou_burgoon2, decreasing = T)][1:5]
data_$text[order(data_$specificity_zhou_burgoon2, decreasing = F)][1:5]
data_$text[order(data_$person_index_weighted, decreasing = F)][1:5]
min(data$person_index_weighted)
data_$text[order(data_$person_index_weighted, decreasing = F)][1:10]
data_$text[order(data_$person_index_weighted, decreasing = F)][1:15]
data_$text[order(data_$person_index_weighted, decreasing = F)][1:25]
data_$text[order(data_$person_index_weighted, decreasing = T)][1:5]
data_$text[order(data_$motion, decreasing = T)][1:5]
data_$text[order(data_$motion, decreasing = F)][1:5]
data_$text[order(data_$concr_mean, decreasing = F)][1:5]
data_$text[order(data_$concr_mean, decreasing = T)][1:5]
